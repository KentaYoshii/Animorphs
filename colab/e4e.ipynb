{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ns90001/Animorphs/blob/master/StyleGAN_plzwork2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xZXVofqLd13",
        "outputId": "5d56d691-a322-43eb-fb82-80533c01d8b0"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'encoder4editing'\n",
        "\n",
        "!git clone https://github.com/cedro3/encoder4editing.git $CODE_DIR\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n",
        "os.chdir(f'./{CODE_DIR}')\n",
        "\n",
        "from argparse import Namespace\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from utils.common import tensor2im\n",
        "from models.psp import pSp  # we use the pSp framework to load the e4e encoder.\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "\n",
        "! pip install --upgrade gdown\n",
        "import os\n",
        "import gdown\n",
        "os.makedirs('pretrained_models', exist_ok=True)\n",
        "gdown.download('https://drive.google.com/u/1/uc?id=1Du_8FzOPKJhk6aJmiOBhAWVe3_6vAyET', 'pretrained_models/e4e_ffhq_encode.pt', quiet=False)\n",
        "\n",
        "! wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "! bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2\n",
        "\n",
        "model_path = 'pretrained_models/e4e_ffhq_encode.pt'  ####\n",
        "ckpt = torch.load(model_path, map_location='cpu')\n",
        "opts = ckpt['opts']\n",
        "opts['checkpoint_path'] = model_path\n",
        "opts= Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()\n",
        "print('Model successfully loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_2T474kLvrQ",
        "outputId": "e3cdd109-56ac-4966-863a-7a13823c8df5"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "if os.path.isdir('align'):\n",
        "     shutil.rmtree('align')\n",
        "os.makedirs('align', exist_ok=True)\n",
        "\n",
        "def run_alignment(image_path):\n",
        "  import dlib\n",
        "  from utils.alignment import align_face\n",
        "  predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "  aligned_image = align_face(filepath=image_path, predictor=predictor) \n",
        "  return aligned_image \n",
        "\n",
        "path = './images'\n",
        "files = sorted(os.listdir(path))\n",
        "for i, file in enumerate(tqdm(files)):\n",
        "  if file=='.ipynb_checkpoints':\n",
        "     continue\n",
        "  input_image = run_alignment(path+'/'+file)\n",
        "  input_image.resize((256,256))\n",
        "  input_image.save('./align/'+file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLBoEd5KMa5o",
        "outputId": "b3de9eaf-a0bb-4bf0-cb0d-2a67a0947bd1"
      },
      "outputs": [],
      "source": [
        "\n",
        "if os.path.isdir('vec_pic'):\n",
        "     shutil.rmtree('vec_pic')\n",
        "os.makedirs('vec_pic', exist_ok=True)\n",
        "\n",
        "if os.path.isdir('vec'):\n",
        "     shutil.rmtree('vec')\n",
        "os.makedirs('vec', exist_ok=True)\n",
        "\n",
        "img_transforms = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "\n",
        "path = './align'\n",
        "files = sorted(os.listdir(path))\n",
        "for i, file in enumerate(tqdm(files)):\n",
        "  if file=='.ipynb_checkpoints':\n",
        "     continue\n",
        "  input_image = Image.open(path+'/'+file)\n",
        "  transformed_image = img_transforms(input_image)\n",
        "  with torch.no_grad():\n",
        "     images, latents = net(transformed_image.unsqueeze(0).to('cuda').float(), randomize_noise=False, return_latents=True)\n",
        "     result_image, latent = images[0], latents[0]\n",
        "     tensor2im(result_image).save('./vec_pic/'+file) \n",
        "     torch.save(latents, './vec/'+file[:-4]+'.pt') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "_v6Z4kB5MfCP",
        "outputId": "3c0dbbac-3113-4757-ca4c-66d06a73acdb"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "def display_pic(folder):\n",
        "    fig = plt.figure(figsize=(30, 40))\n",
        "    files = os.listdir(folder)\n",
        "    files.sort()\n",
        "    for i, file in enumerate(files):\n",
        "        img = Image.open(folder+'/'+file)    \n",
        "        images = np.asarray(img)\n",
        "        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images)\n",
        "        ax.imshow(image_plt)\n",
        "        ax.set_xlabel(folder+'/'+file, fontsize=15)               \n",
        "    plt.show()\n",
        "    plt.close()  \n",
        "\n",
        "display_pic('align')\n",
        "display_pic('vec_pic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AVw94OzQMhJw"
      },
      "outputs": [],
      "source": [
        "latent = \"05.pt\"#@param {type:\"string\"}\n",
        "direction = \"age\" #@param [\"age\", \"pose\", \"smile\", \"age+pose\"] {allow-input: true}\n",
        "min = -50 #@param {type:\"slider\", min:-50, max:0, step:10}\n",
        "max = 50 #@param {type:\"slider\", min:0, max:50, step:10}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJvg5DcUMp2u",
        "outputId": "a44954d5-35a0-4b0c-91d5-24017be01d9b"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "if os.path.isdir('pic'):\n",
        "     shutil.rmtree('pic')\n",
        "os.makedirs('pic', exist_ok=True)\n",
        "\n",
        "from editings import latent_editor\n",
        "from tqdm import trange\n",
        "\n",
        "folder = 'vec'\n",
        "latents = torch.load(folder+'/'+latent)\n",
        "editor = latent_editor.LatentEditor(net.decoder, False)\n",
        "\n",
        "interfacegan_directions = {\n",
        "        'age': 'editings/interfacegan_directions/age.pt',\n",
        "        'smile': 'editings/interfacegan_directions/smile.pt',\n",
        "        'pose': 'editings/interfacegan_directions/pose.pt',\n",
        "        'age+pose':  'editings/interfacegan_directions/age+pose.pt'\n",
        "    }\n",
        "\n",
        "interfacegan_direction = torch.load(interfacegan_directions[direction]).cuda()\n",
        "cnt = 0\n",
        "\n",
        "for i in trange(0, min, -1, desc='0 -> min'):\n",
        "     result = editor.apply_interfacegan(latents, interfacegan_direction, factor=i).resize((512,512))\n",
        "     result.save('./pic/'+str(cnt).zfill(6)+'.jpg')\n",
        "     cnt +=1\n",
        "\n",
        "for i in trange(min, max, desc='min -> max'):\n",
        "     result = editor.apply_interfacegan(latents, interfacegan_direction, factor=i).resize((512,512))\n",
        "     result.save('./pic/'+str(cnt).zfill(6)+'.jpg')\n",
        "     cnt +=1\n",
        "\n",
        "for i in trange(max, 0, -1, desc='max -> 0'):\n",
        "     result = editor.apply_interfacegan(latents, interfacegan_direction, factor=i).resize((512,512))\n",
        "     result.save('./pic/'+str(cnt).zfill(6)+'.jpg')\n",
        "     cnt +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "id": "-5TdjgRiMyLa",
        "outputId": "e0c571de-0304-4c22-cbe8-6314f5c884a6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "if os.path.exists('./output.mp4'):\n",
        "   os.remove('./output.mp4')\n",
        "\n",
        "! ffmpeg -r 30 -i pic/%6d.jpg\\\n",
        "               -vcodec libx264 -pix_fmt yuv420p output.mp4\n",
        "\n",
        "import shutil\n",
        "os.makedirs('movie', exist_ok=True)\n",
        "shutil.copy('output.mp4', 'movie/'+direction+'_'+latent[:-3]+'.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "9ZPEtpp3M2Uc",
        "outputId": "a5d234ee-085d-42c9-e329-ac0d2104b791"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('./output.mp4', 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"50%\" height=\"50%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdRWbpsQgmys"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNKl5kdPQ/Eq4bDkoZ5Ryx+",
      "include_colab_link": true,
      "name": "StyleGAN_plzwork2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
